{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbc155f-56d2-47fa-8cce-f2e98d16664e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T20:47:28.022945Z",
     "iopub.status.busy": "2024-07-14T20:47:28.022782Z",
     "iopub.status.idle": "2024-07-14T20:49:53.661211Z",
     "shell.execute_reply": "2024-07-14T20:49:53.658750Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "# Write initial message to mapping.txt\n",
    "with open('mapping.txt', 'w') as file:\n",
    "    file.write(\"Processing Started. The Background processes will be shown here \\n\\n\")\n",
    "\n",
    "# Load input CSV and reference FMP CSV\n",
    "input_csv_path = 'uploads/input.csv'\n",
    "concatenated_df = pd.read_csv(input_csv_path)\n",
    "fmp = pd.read_csv(\"Reference_FMP.csv\")\n",
    "fmp = fmp.sort_values(by=['State Name', 'd_name', 'sd_name'])\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "# Function to get the best match\n",
    "def get_best_match(name, list2):\n",
    "    best_match = process.extractOne(name, list2)\n",
    "    return best_match[0] if best_match else name\n",
    "\n",
    "# Mapping for State Names\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    file.write(\"Step 1 started. Mapping State Names \\n\\n\")\n",
    "    \n",
    "mapping = {name: get_best_match(name, list(fmp['State Name'].unique())) for name in concatenated_df['StateName'].unique()}\n",
    "\n",
    "# Function to correct name using mapping\n",
    "def correct_name(name, mapping):\n",
    "    return mapping.get(name, name)\n",
    "\n",
    "# Write the mapping to a text file\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    file.write(\"Mapping created for State Names \\n\")\n",
    "    file.write(str(mapping))\n",
    "    file.write(\"\\n\\n\")\n",
    "\n",
    "# Apply the corrected State Names\n",
    "concatenated_df['Matched State Name'] = concatenated_df['StateName'].apply(lambda x: correct_name(x, mapping))\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "# Function to get the best match with cache for District Names\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    file.write(\"Step 2 started. Mapping District Names \\n\\n\")\n",
    "\n",
    "def get_best_match_with_cache_district(row, fmp, cache):\n",
    "    state = row['Matched State Name']\n",
    "    district = row['DistrictName']\n",
    "    \n",
    "    if state not in cache:\n",
    "        with open('mapping.txt', 'a') as file:\n",
    "            if str(cache) != \"{}\":\n",
    "                file.write(f\"Mapping created for {list(cache.keys())[-1]}'s District Names \\n\")\n",
    "                file.write(str(cache[list(cache.keys())[-1]]))\n",
    "                file.write(\"\\n\\n\")\n",
    "        cache[state] = {}\n",
    "    \n",
    "    if district not in cache[state]:\n",
    "        fmp_state = fmp[fmp['State Name'] == state]\n",
    "        match, score = process.extractOne(district, fmp_state['d_name'].unique(), scorer=fuzz.token_sort_ratio)\n",
    "        cache[state][district] = match\n",
    "    \n",
    "    return cache[state][district]\n",
    "\n",
    "cache = {}\n",
    "concatenated_df['Matched District name'] = concatenated_df.apply(lambda row: get_best_match_with_cache_district(row, fmp, cache), axis=1)\n",
    "\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    if str(cache) != \"{}\":\n",
    "        file.write(f\"Mapping created for {list(cache.keys())[-1]}'s District Names \\n\")\n",
    "        file.write(str(cache[list(cache.keys())[-1]]))\n",
    "        file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "# Function to get the best match with cache for Sub-District Names\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    file.write(\"Step 3 started. Mapping Block Names \\n\\n\")\n",
    "    \n",
    "def get_best_match_with_cache_subdistrict(row, fmp, cache, last_state):\n",
    "    state = row['Matched State Name']\n",
    "    district = row['Matched District name']\n",
    "    sub_district = row['BlockName']\n",
    "    \n",
    "    if state != last_state[0]:\n",
    "        cache.clear()  \n",
    "        last_state[0] = state  \n",
    "    \n",
    "    fmp_state = fmp[fmp['State Name'] == state]\n",
    "    fmp_district = fmp_state[fmp_state['d_name'] == district]\n",
    "    \n",
    "    if district not in cache:\n",
    "        with open('mapping.txt', 'a') as file:\n",
    "            if str(cache) != \"{}\":\n",
    "                file.write(f\"Mapping created for {list(cache.keys())[-1]}'s Block Names \\n\")\n",
    "                file.write(str(cache[list(cache.keys())[-1]]))\n",
    "                file.write(\"\\n\\n\")\n",
    "        cache[district] = {}\n",
    "\n",
    "    if sub_district not in cache[district]:\n",
    "        best_match = process.extractOne(sub_district, fmp_district['sd_name'].unique(), scorer=fuzz.token_sort_ratio)[0]\n",
    "        cache[district][sub_district] = best_match\n",
    "\n",
    "    return cache[district][sub_district]\n",
    "\n",
    "cache = {}\n",
    "last_state = [None]\n",
    "concatenated_df['Matched SubDistrict name'] = concatenated_df.apply(lambda row: get_best_match_with_cache_subdistrict(row, fmp, cache, last_state), axis=1)\n",
    "\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    if str(cache) != \"{}\":\n",
    "        file.write(f\"Mapping created for {list(cache.keys())[-1]}'s Block Names \\n\")\n",
    "        file.write(str(cache[list(cache.keys())[-1]]))\n",
    "        file.write(\"\\n\\n\")\n",
    "                \n",
    "######################################################################################\n",
    "\n",
    "# Function to get the best match with cache for Village Names\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    file.write(\"Step 4 started. Mapping Villages Names \\n\\n\")\n",
    "    \n",
    "def get_best_match_with_cache_village(row, fmp, cache, last_state):\n",
    "    state = row['Matched State Name']\n",
    "    district = row['Matched District name']\n",
    "    village = row['VillageName']  \n",
    "    \n",
    "    if state != last_state[0]:\n",
    "        cache.clear()\n",
    "        last_state[0] = state  \n",
    "    \n",
    "    fmp_state = fmp[fmp['State Name'] == state]\n",
    "    fmp_district = fmp_state[fmp_state['d_name'] == district]\n",
    "    \n",
    "    if district not in cache:\n",
    "        with open('mapping.txt', 'a') as file:\n",
    "            if str(cache) != \"{}\":\n",
    "                file.write(f\"Mapping created for {list(cache.keys())[-1]}'s Villages Names \\n\")\n",
    "                file.write(str(cache[list(cache.keys())[-1]]))\n",
    "                file.write(\"\\n\\n\")\n",
    "        \n",
    "        cache[district] = {}\n",
    "    \n",
    "    if village not in cache[district]:\n",
    "        best_match = process.extractOne(village, fmp_district['tv_name'].unique(), scorer=fuzz.token_sort_ratio)[0]\n",
    "        cache[district][village] = best_match\n",
    "\n",
    "    return cache[district][village]\n",
    "\n",
    "cache = {}\n",
    "last_state = [None]\n",
    "concatenated_df['Matched Village name'] = concatenated_df.apply(lambda row: get_best_match_with_cache_village(row, fmp, cache, last_state), axis=1)\n",
    "\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    if str(cache) != \"{}\":\n",
    "        file.write(f\"Mapping created for {list(cache.keys())[-1]}'s Villages Names \\n\")\n",
    "        file.write(str(cache[list(cache.keys())[-1]]))\n",
    "        file.write(\"\\n\\n\")\n",
    "                \n",
    "######################################################################################\n",
    "\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    file.write(\"Step 5 started. Merging \\n\\n\")\n",
    "\n",
    "# Rename columns to match FMP\n",
    "concatenated_df = concatenated_df.rename(columns={\n",
    "    'Matched State Name': 'State Name',\n",
    "    'Matched District name': 'd_name',\n",
    "    'Matched SubDistrict name': 'sd_name',\n",
    "    'Matched Village name': 'tv_name'\n",
    "})\n",
    "\n",
    "# Merge concatenated_df with fmp\n",
    "fmp_con = pd.merge(fmp, concatenated_df, on=['State Name', 'd_name', 'sd_name', 'tv_name'], how='inner')\n",
    "\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    file.write(\"Step 6 started. Creating shrid column \\n\\n\")\n",
    "\n",
    "# Create shrid2 column\n",
    "fmp_con['shrid2'] = fmp_con.apply(lambda row: f\"11-{row['pc11_s_id']}-{row['pc11_d_id']}-0{row['pc11_sd_id']}-{row['pc11_tv_id']}\", axis=1)\n",
    "\n",
    "# Load vcf and merge with fmp_con\n",
    "with open('mapping.txt', 'a') as file:\n",
    "    file.write(\"Final Step started. Merging \\n\\n\")\n",
    "    \n",
    "vcf = pd.read_csv(\"vcf_shrid.csv\")\n",
    "fmp_con = pd.merge(fmp_con, vcf, on='shrid2', how='inner')\n",
    "\n",
    "# Save the final dataframe to CSV\n",
    "output_csv_path = 'outputs/output.csv'\n",
    "fmp_con.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d423c2b-068f-4747-85df-ac1f3dcf5b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
